{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNeaH5LyiDvTXquHiPFVOjS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hwarang97/Image_classification/blob/main/VGG16_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VGG\n",
        "- 16, 19 등 뒤에 붙는 숫자는 구성된 층의 갯수\n",
        "- 쉬운 구조와 성능 덕분에 우승모델(Googlenet)보다 인기가 더 많음\n",
        "- 핵심\n",
        "  - 모델 깊이와 성능의 관계 파악\n",
        "    - 더 깊이 만들기 위해서 커널을 3x3을 고정\n",
        "    - 큰 필터를 한번 적용하는것보다 작은 필터를 여러번 적용하는것이 성능은 같은데 파라미터 수가 더 적음\n",
        "    - 작은 필터를 적용하니 비선형성이 증가하여 특성을 잘 나타냄\n",
        "\n",
        "- input : 224 x 224 x 3"
      ],
      "metadata": {
        "id": "g73J0uCGneGK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iEDL_XQ3XrNE"
      },
      "outputs": [],
      "source": [
        "from torch.nn.modules.activation import Softmax \n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import * \n",
        "from torch.nn.modules import dropout\n",
        "from torch.nn.modules.adaptive import Linear\n",
        "from torch.nn.modules.pooling import MaxPool2d\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu' "
      ],
      "metadata": {
        "id": "oLB1Wot7rbPJ",
        "outputId": "2cb3ba00-f130-4ff5-9741-be70a1f455e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-0c8118a4c814>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'cuda'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'cpu'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Retrieve data directly from Stanford data source\n",
        "# !wget http://cs231n.stanford.edu/tiny-imagenet-200.zip\n",
        "\n",
        "# # Unzip raw zip file\n",
        "# !unzip -qq 'tiny-imagenet-200.zip'"
      ],
      "metadata": {
        "id": "KsSiZSibwiPP",
        "outputId": "be9576c3-123a-43f1-8088-e3d6ef570ea7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-12-29 13:33:40--  http://cs231n.stanford.edu/tiny-imagenet-200.zip\n",
            "Resolving cs231n.stanford.edu (cs231n.stanford.edu)... 171.64.68.10\n",
            "Connecting to cs231n.stanford.edu (cs231n.stanford.edu)|171.64.68.10|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 248100043 (237M) [application/zip]\n",
            "Saving to: ‘tiny-imagenet-200.zip’\n",
            "\n",
            "tiny-imagenet-200.z 100%[===================>] 236.61M  38.8MB/s    in 7.3s    \n",
            "\n",
            "2022-12-29 13:33:48 (32.2 MB/s) - ‘tiny-imagenet-200.zip’ saved [248100043/248100043]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Define main data directory\n",
        "# DATA_DIR = 'tiny-imagenet-200'\n",
        "\n",
        "# # Define training and validation data paths\n",
        "# TRAIN_DIR = os.path.join(DATA_DIR, 'train')\n",
        "# TEST_DIR = os.path.join(DATA_DIR, 'test')\n",
        "\n",
        "# training_data = datasets.ImageFolder(root = TRAIN_DIR, \n",
        "#                                      transform=transforms.Compose([ # transform : 이미지 특징들에 적용\n",
        "#                                          Resize(224),\n",
        "#                                          ToTensor(), # 텐서로 만들고, 0~1 사이 값으로 스케일링\n",
        "#                                      ]))\n",
        "# test_data = datasets.ImageFolder(root = TEST_DIR, transform=transforms.Compose([\n",
        "#                                          Resize(224),\n",
        "#                                          ToTensor(),\n",
        "#                                      ]))\n",
        "\n",
        "# sample = training_data[0][0]\n",
        "# print(sample.shape, sample.dtype, sample.max(), sample.min()) # 제대로 변환되었는지 확인"
      ],
      "metadata": {
        "id": "8u4N9MgW4eAk",
        "outputId": "4719b6b0-5031-49a5-c013-47b605003ba1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 224, 224]) torch.float32 tensor(1.) tensor(0.0235)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터가 문제인지 모델이 문제인지, fashion으로 새로 만들어보고 제대로 학습하는지 확인해보자."
      ],
      "metadata": {
        "id": "KjhwYz2sNN-J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(training_data, batch_size=32) # batch_size가 작으니까 너무 불안정하다. 128정도 이상은 되야하지 않을까\n",
        "test_dataloader = DataLoader(test_data, batch_size=32)"
      ],
      "metadata": {
        "id": "FNfWP2qbd4lv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 추가학습\n",
        "- 직접 데이터셋을 구성하고 불러오는 방법\n",
        "- https://data-panic.tistory.com/13\n",
        "\n",
        "- 참조한 페이지(tiny-imagenet-200 관련)\n",
        "- https://towardsdatascience.com/pytorch-ignite-classifying-tiny-imagenet-with-efficientnet-e5b1768e5e8f"
      ],
      "metadata": {
        "id": "Q209PSg74rV7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class VGG16(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.flatten = nn.Flatten()\n",
        "\n",
        "    \"\"\"Conv layers\"\"\"\n",
        "    self.conv_relu_stack = nn.Sequential(\n",
        "        nn.Conv2d(3, 64, 3, padding=1),   # conv1_1\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(64, 64, 3, padding=1),  # conv1_2\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2),\n",
        "        nn.Conv2d(64, 128, 3, padding=1), # conv2_1\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(128, 128, 3, padding=1), # conv2_2\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2),\n",
        "        nn.Conv2d(128, 256, 3, padding=1), # conv3_1\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(256, 256, 3, padding=1), # conv3_2\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(256, 256, 3, padding=1), # conv3_3\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2),\n",
        "        nn.Conv2d(256, 512, 3, padding=1), # conv4_1\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(512, 512, 3, padding=1), # conv4_2\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(512, 512, 3, padding=1), # conv4_3\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2),    \n",
        "        nn.Conv2d(512, 512, 3, padding=1), # conv5_1\n",
        "        nn.ReLU(),           \n",
        "        nn.Conv2d(512, 512, 3, padding=1), # conv5_2\n",
        "        nn.ReLU(),          \n",
        "        nn.Conv2d(512, 512, 3, padding=1), # conv5_3\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2),\n",
        "    )\n",
        "\n",
        "    \"\"\"FC layers\"\"\"\n",
        "    self.linear_relu_stack = nn.Sequential(\n",
        "        nn.Linear(7*7*512, 4096),  \n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.5),        # 드롭 아웃은 왜 활성화 다음에 쓸까, 전에 쓰면 계산할것도 줄어들지 않나\n",
        "        nn.Linear(4096, 4096),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.5),\n",
        "        nn.Linear(4096,1000)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x1 = self.conv_relu_stack(x)\n",
        "    x2 = self.flatten(x1)\n",
        "    logits = self.linear_relu_stack(x2)\n",
        "    return logits"
      ],
      "metadata": {
        "id": "B6B6Wx-Mr0Kf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "  size = len(dataloader.dataset)\n",
        "  for step, (X, y) in enumerate(dataloader, 1): # 전체 이미지를 batch_size만큼 묶어서 전달\n",
        "    X = X.to(device)\n",
        "    y = y.to(device)\n",
        "    pred = model(X)\n",
        "    loss = loss_fn(pred, y)\n",
        "\n",
        "    optimizer.zero_grad() # 전에 역전파로 얻었던 w 기울기를 0으로 만들어주기. 안그러면 누적되어 점점커짐\n",
        "    loss.backward() # 역전파\n",
        "    optimizer.step() # 오차에 기여한 만큼 파라미터를 갱신\n",
        "\n",
        "    if step % 10 == 0:\n",
        "      loss, current = loss.item(), step * len(X)\n",
        "      print(f'loss : {loss:>7f} [{current:>5d}/{size:>5d}]')\n",
        "\n",
        "\n",
        "def test_loop(dataloader, model, loss_fn):\n",
        "  size = len(dataloader.dataset)\n",
        "  num_batches = len(dataloader)\n",
        "  test_loss, correct = 0, 0\n",
        "\n",
        "  with torch.no_grad(): # grad를 저장하지 않음\n",
        "    for X, y in dataloader:\n",
        "      X = X.to(device)\n",
        "      y = y.to(device)\n",
        "      pred = model(X)\n",
        "      test_loss += loss_fn(pred, y).item() # 오차값을 누적\n",
        "      correct += (pred.argmax(1)==y).type(torch.float).sum().item() # 몇개 맞췄는지 기록\n",
        "\n",
        "  test_loss /= num_batches # loss 값의 평균\n",
        "  correct /= size          # 정확도 평균\n",
        "  print(f'Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n') # 0.1f는 뭐지 -> 소수점 한자리까지 표현(?)"
      ],
      "metadata": {
        "id": "HqcrN4y2X9YZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = VGG16().to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "id": "U2d-A4hAbl5z",
        "outputId": "9bba534e-a449-4da7-902e-08e937ff245d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VGG16(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (conv_relu_stack): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU()\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): ReLU()\n",
            "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): ReLU()\n",
            "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU()\n",
            "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU()\n",
            "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): ReLU()\n",
            "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): ReLU()\n",
            "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (20): ReLU()\n",
            "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (22): ReLU()\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): ReLU()\n",
            "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (27): ReLU()\n",
            "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (29): ReLU()\n",
            "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 추가 학습\n",
        "- print f format의 정렬기능\n",
        "  - 중괄호{}안에 변수 옆에 : 를 입력\n",
        "  - < : 왼쪽정렬\n",
        "  - \\> : 오른정렬\n",
        "  - \\^ : 중앙정렬\n",
        "  - 숫자 : 몇칸으로 표현할지"
      ],
      "metadata": {
        "id": "mYlU6HlUY-1s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 1e-2\n",
        "epochs = 1\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate) # 미니배치면 불완전하지만 SDG보다는 빠르게 최적 파라미에 도달한다\n",
        "\n",
        "for t in range(epochs):\n",
        "  print(f'Epoch {t+1}\\n-----------------------------')\n",
        "  train_loop(train_dataloader, model, loss_fn, optimizer)\n",
        "  test_loop(test_dataloader, model, loss_fn)\n",
        "print('DONE!!!!!!!!!!!!!!!!!!!!!!!') # GPU RAM 값이 부족하면 kernel을 restart해보고, 그래도 찼다면 batch_size를 줄이고 이걸 반복"
      ],
      "metadata": {
        "id": "KrSrapIocv-_",
        "outputId": "ba9f1064-d683-450e-f6dc-4cf016f8a4a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-----------------------------\n",
            "loss : 6.775857 [  320/100000]\n",
            "loss : 6.854997 [  640/100000]\n",
            "loss : 6.713550 [  960/100000]\n",
            "loss : 6.812537 [ 1280/100000]\n",
            "loss : 6.888543 [ 1600/100000]\n",
            "loss : 6.743188 [ 1920/100000]\n",
            "loss : 6.814485 [ 2240/100000]\n",
            "loss : 6.891642 [ 2560/100000]\n",
            "loss : 6.743404 [ 2880/100000]\n",
            "loss : 6.846145 [ 3200/100000]\n",
            "loss : 6.819551 [ 3520/100000]\n",
            "loss : 6.748758 [ 3840/100000]\n",
            "loss : 6.846713 [ 4160/100000]\n",
            "loss : 6.690723 [ 4480/100000]\n",
            "loss : 6.764525 [ 4800/100000]\n",
            "loss : 6.847092 [ 5120/100000]\n",
            "loss : 6.681594 [ 5440/100000]\n",
            "loss : 6.782244 [ 5760/100000]\n",
            "loss : 6.902182 [ 6080/100000]\n",
            "loss : 6.731118 [ 6400/100000]\n",
            "loss : 6.814731 [ 6720/100000]\n",
            "loss : 6.912586 [ 7040/100000]\n",
            "loss : 6.725810 [ 7360/100000]\n",
            "loss : 6.822799 [ 7680/100000]\n",
            "loss : 6.621541 [ 8000/100000]\n",
            "loss : 6.705748 [ 8320/100000]\n",
            "loss : 6.850522 [ 8640/100000]\n",
            "loss : 6.616325 [ 8960/100000]\n",
            "loss : 6.721533 [ 9280/100000]\n",
            "loss : 6.850364 [ 9600/100000]\n",
            "loss : 6.530475 [ 9920/100000]\n",
            "loss : 6.657182 [10240/100000]\n",
            "loss : 6.852275 [10560/100000]\n",
            "loss : 6.062894 [10880/100000]\n",
            "loss : 5.845178 [11200/100000]\n",
            "loss : 7.584822 [11520/100000]\n",
            "loss : 0.026008 [11840/100000]\n",
            "loss : 1.811157 [12160/100000]\n",
            "loss : 0.013619 [12480/100000]\n",
            "loss : 0.038576 [12800/100000]\n",
            "loss : 3.053650 [13120/100000]\n",
            "loss : 0.015296 [13440/100000]\n",
            "loss : 0.044186 [13760/100000]\n",
            "loss : 4.865232 [14080/100000]\n",
            "loss : 0.022135 [14400/100000]\n",
            "loss : 0.129365 [14720/100000]\n",
            "loss : 9.683543 [15040/100000]\n",
            "loss : 0.027983 [15360/100000]\n",
            "loss : 0.510468 [15680/100000]\n",
            "loss : 0.016272 [16000/100000]\n",
            "loss : 0.046909 [16320/100000]\n",
            "loss : 3.068436 [16640/100000]\n",
            "loss : 0.018394 [16960/100000]\n",
            "loss : 0.060242 [17280/100000]\n",
            "loss : 4.482529 [17600/100000]\n",
            "loss : 0.023879 [17920/100000]\n",
            "loss : 0.115380 [18240/100000]\n",
            "loss : 5.974625 [18560/100000]\n",
            "loss : 0.032950 [18880/100000]\n",
            "loss : 0.661956 [19200/100000]\n",
            "loss : 8.081822 [19520/100000]\n",
            "loss : 0.052122 [19840/100000]\n",
            "loss : 2.270979 [20160/100000]\n",
            "loss : 0.022701 [20480/100000]\n",
            "loss : 0.070406 [20800/100000]\n",
            "loss : 3.889601 [21120/100000]\n",
            "loss : 0.027600 [21440/100000]\n",
            "loss : 0.136984 [21760/100000]\n",
            "loss : 5.365522 [22080/100000]\n",
            "loss : 0.036843 [22400/100000]\n",
            "loss : 0.346646 [22720/100000]\n",
            "loss : 9.891508 [23040/100000]\n",
            "loss : 0.046658 [23360/100000]\n",
            "loss : 1.820910 [23680/100000]\n",
            "loss : 0.025568 [24000/100000]\n",
            "loss : 0.070457 [24320/100000]\n",
            "loss : 3.629293 [24640/100000]\n",
            "loss : 0.030770 [24960/100000]\n",
            "loss : 0.131795 [25280/100000]\n",
            "loss : 5.011574 [25600/100000]\n",
            "loss : 0.038041 [25920/100000]\n",
            "loss : 0.383417 [26240/100000]\n",
            "loss : 6.417475 [26560/100000]\n",
            "loss : 0.045473 [26880/100000]\n",
            "loss : 1.408873 [27200/100000]\n",
            "loss : 7.910246 [27520/100000]\n",
            "loss : 0.062237 [27840/100000]\n",
            "loss : 2.842013 [28160/100000]\n",
            "loss : 0.032355 [28480/100000]\n",
            "loss : 0.126525 [28800/100000]\n",
            "loss : 4.521658 [29120/100000]\n",
            "loss : 0.041764 [29440/100000]\n",
            "loss : 0.234269 [29760/100000]\n",
            "loss : 5.790692 [30080/100000]\n",
            "loss : 0.047740 [30400/100000]\n",
            "loss : 0.805162 [30720/100000]\n",
            "loss : 10.164403 [31040/100000]\n",
            "loss : 0.067562 [31360/100000]\n",
            "loss : 2.559981 [31680/100000]\n",
            "loss : 0.030288 [32000/100000]\n",
            "loss : 0.094393 [32320/100000]\n",
            "loss : 4.135007 [32640/100000]\n",
            "loss : 0.035867 [32960/100000]\n",
            "loss : 0.264588 [33280/100000]\n",
            "loss : 5.241772 [33600/100000]\n",
            "loss : 0.049676 [33920/100000]\n",
            "loss : 0.804640 [34240/100000]\n",
            "loss : 6.831491 [34560/100000]\n",
            "loss : 0.064773 [34880/100000]\n",
            "loss : 1.930325 [35200/100000]\n",
            "loss : 7.773225 [35520/100000]\n",
            "loss : 0.099753 [35840/100000]\n",
            "loss : 3.642949 [36160/100000]\n",
            "loss : 0.039568 [36480/100000]\n",
            "loss : 0.193230 [36800/100000]\n",
            "loss : 4.703491 [37120/100000]\n",
            "loss : 0.047941 [37440/100000]\n",
            "loss : 0.457427 [37760/100000]\n",
            "loss : 5.751773 [38080/100000]\n",
            "loss : 0.054757 [38400/100000]\n",
            "loss : 1.330285 [38720/100000]\n",
            "loss : 10.503049 [39040/100000]\n",
            "loss : 0.086217 [39360/100000]\n",
            "loss : 2.918339 [39680/100000]\n",
            "loss : 0.029566 [40000/100000]\n",
            "loss : 0.152865 [40320/100000]\n",
            "loss : 4.329189 [40640/100000]\n",
            "loss : 0.052082 [40960/100000]\n",
            "loss : 0.274657 [41280/100000]\n",
            "loss : 5.429776 [41600/100000]\n",
            "loss : 0.044899 [41920/100000]\n",
            "loss : 1.198099 [42240/100000]\n",
            "loss : 6.970613 [42560/100000]\n",
            "loss : 0.082464 [42880/100000]\n",
            "loss : 2.285619 [43200/100000]\n",
            "loss : 7.854069 [43520/100000]\n",
            "loss : 0.129951 [43840/100000]\n",
            "loss : 3.723640 [44160/100000]\n",
            "loss : 0.051633 [44480/100000]\n",
            "loss : 0.266101 [44800/100000]\n",
            "loss : 4.786189 [45120/100000]\n",
            "loss : 0.052664 [45440/100000]\n",
            "loss : 0.813847 [45760/100000]\n",
            "loss : 6.093226 [46080/100000]\n",
            "loss : 0.067255 [46400/100000]\n",
            "loss : 1.862810 [46720/100000]\n",
            "loss : 10.409126 [47040/100000]\n",
            "loss : 0.104009 [47360/100000]\n",
            "loss : 3.205542 [47680/100000]\n",
            "loss : 0.041209 [48000/100000]\n",
            "loss : 0.197713 [48320/100000]\n",
            "loss : 4.343132 [48640/100000]\n",
            "loss : 0.055618 [48960/100000]\n",
            "loss : 0.485038 [49280/100000]\n",
            "loss : 5.334996 [49600/100000]\n",
            "loss : 0.073177 [49920/100000]\n",
            "loss : 1.420428 [50240/100000]\n",
            "loss : 7.354550 [50560/100000]\n",
            "loss : 0.111875 [50880/100000]\n",
            "loss : 2.710273 [51200/100000]\n",
            "loss : 7.653856 [51520/100000]\n",
            "loss : 0.165691 [51840/100000]\n",
            "loss : 3.798667 [52160/100000]\n",
            "loss : 0.044381 [52480/100000]\n",
            "loss : 0.334334 [52800/100000]\n",
            "loss : 4.934445 [53120/100000]\n",
            "loss : 0.060900 [53440/100000]\n",
            "loss : 0.894937 [53760/100000]\n",
            "loss : 6.293868 [54080/100000]\n",
            "loss : 0.099148 [54400/100000]\n",
            "loss : 2.079176 [54720/100000]\n",
            "loss : 10.224572 [55040/100000]\n",
            "loss : 0.135353 [55360/100000]\n",
            "loss : 3.119355 [55680/100000]\n",
            "loss : 0.047239 [56000/100000]\n",
            "loss : 0.247516 [56320/100000]\n",
            "loss : 4.489421 [56640/100000]\n",
            "loss : 0.069565 [56960/100000]\n",
            "loss : 0.561169 [57280/100000]\n",
            "loss : 5.592068 [57600/100000]\n",
            "loss : 0.093375 [57920/100000]\n",
            "loss : 1.705495 [58240/100000]\n",
            "loss : 7.543026 [58560/100000]\n",
            "loss : 0.135634 [58880/100000]\n",
            "loss : 2.973680 [59200/100000]\n",
            "loss : 7.637081 [59520/100000]\n",
            "loss : 0.227030 [59840/100000]\n",
            "loss : 3.930635 [60160/100000]\n",
            "loss : 0.065420 [60480/100000]\n",
            "loss : 0.459198 [60800/100000]\n",
            "loss : 5.249163 [61120/100000]\n",
            "loss : 0.093820 [61440/100000]\n",
            "loss : 1.391154 [61760/100000]\n",
            "loss : 6.548450 [62080/100000]\n",
            "loss : 0.116289 [62400/100000]\n",
            "loss : 2.221416 [62720/100000]\n",
            "loss : 10.562673 [63040/100000]\n",
            "loss : 0.199475 [63360/100000]\n",
            "loss : 3.360625 [63680/100000]\n",
            "loss : 0.058853 [64000/100000]\n",
            "loss : 0.314692 [64320/100000]\n",
            "loss : 4.593901 [64640/100000]\n",
            "loss : 0.088274 [64960/100000]\n",
            "loss : 0.856306 [65280/100000]\n",
            "loss : 5.718910 [65600/100000]\n",
            "loss : 0.102420 [65920/100000]\n",
            "loss : 1.783691 [66240/100000]\n",
            "loss : 7.663482 [66560/100000]\n",
            "loss : 0.137058 [66880/100000]\n",
            "loss : 2.999898 [67200/100000]\n",
            "loss : 7.255426 [67520/100000]\n",
            "loss : 0.231150 [67840/100000]\n",
            "loss : 4.219789 [68160/100000]\n",
            "loss : 0.069730 [68480/100000]\n",
            "loss : 0.552150 [68800/100000]\n",
            "loss : 5.114986 [69120/100000]\n",
            "loss : 0.095120 [69440/100000]\n",
            "loss : 1.183276 [69760/100000]\n",
            "loss : 6.496601 [70080/100000]\n",
            "loss : 0.115489 [70400/100000]\n",
            "loss : 2.379507 [70720/100000]\n",
            "loss : 10.665875 [71040/100000]\n",
            "loss : 0.203493 [71360/100000]\n",
            "loss : 3.607228 [71680/100000]\n",
            "loss : 0.061873 [72000/100000]\n",
            "loss : 0.399009 [72320/100000]\n",
            "loss : 4.682980 [72640/100000]\n",
            "loss : 0.087239 [72960/100000]\n",
            "loss : 0.780973 [73280/100000]\n",
            "loss : 5.803829 [73600/100000]\n",
            "loss : 0.113268 [73920/100000]\n",
            "loss : 1.789907 [74240/100000]\n",
            "loss : 7.708229 [74560/100000]\n",
            "loss : 0.161307 [74880/100000]\n",
            "loss : 3.114424 [75200/100000]\n",
            "loss : 7.540359 [75520/100000]\n",
            "loss : 0.297057 [75840/100000]\n",
            "loss : 4.029093 [76160/100000]\n",
            "loss : 0.078231 [76480/100000]\n",
            "loss : 0.639087 [76800/100000]\n",
            "loss : 5.293344 [77120/100000]\n",
            "loss : 0.090079 [77440/100000]\n",
            "loss : 1.313510 [77760/100000]\n",
            "loss : 6.591704 [78080/100000]\n",
            "loss : 0.117483 [78400/100000]\n",
            "loss : 2.461377 [78720/100000]\n",
            "loss : 10.400146 [79040/100000]\n",
            "loss : 0.181129 [79360/100000]\n",
            "loss : 3.581357 [79680/100000]\n",
            "loss : 0.067527 [80000/100000]\n",
            "loss : 0.430660 [80320/100000]\n",
            "loss : 4.522260 [80640/100000]\n",
            "loss : 0.085953 [80960/100000]\n",
            "loss : 0.741103 [81280/100000]\n",
            "loss : 5.901624 [81600/100000]\n",
            "loss : 0.095671 [81920/100000]\n",
            "loss : 1.898803 [82240/100000]\n",
            "loss : 7.762215 [82560/100000]\n",
            "loss : 0.153061 [82880/100000]\n",
            "loss : 2.933790 [83200/100000]\n",
            "loss : 7.137083 [83520/100000]\n",
            "loss : 0.266442 [83840/100000]\n",
            "loss : 4.063780 [84160/100000]\n",
            "loss : 0.077704 [84480/100000]\n",
            "loss : 0.687108 [84800/100000]\n",
            "loss : 5.304688 [85120/100000]\n",
            "loss : 0.100805 [85440/100000]\n",
            "loss : 1.364163 [85760/100000]\n",
            "loss : 6.647402 [86080/100000]\n",
            "loss : 0.139232 [86400/100000]\n",
            "loss : 2.614492 [86720/100000]\n",
            "loss : 10.670366 [87040/100000]\n",
            "loss : 0.212950 [87360/100000]\n",
            "loss : 3.715518 [87680/100000]\n",
            "loss : 0.062841 [88000/100000]\n",
            "loss : 0.412776 [88320/100000]\n",
            "loss : 4.809787 [88640/100000]\n",
            "loss : 0.102962 [88960/100000]\n",
            "loss : 0.814528 [89280/100000]\n",
            "loss : 5.842930 [89600/100000]\n",
            "loss : 0.116078 [89920/100000]\n",
            "loss : 2.001409 [90240/100000]\n",
            "loss : 7.867754 [90560/100000]\n",
            "loss : 0.212477 [90880/100000]\n",
            "loss : 3.288720 [91200/100000]\n",
            "loss : 7.133353 [91520/100000]\n",
            "loss : 0.282634 [91840/100000]\n",
            "loss : 4.081004 [92160/100000]\n",
            "loss : 0.100343 [92480/100000]\n",
            "loss : 0.667445 [92800/100000]\n",
            "loss : 5.377820 [93120/100000]\n",
            "loss : 0.104598 [93440/100000]\n",
            "loss : 1.481271 [93760/100000]\n",
            "loss : 6.573602 [94080/100000]\n",
            "loss : 0.130225 [94400/100000]\n",
            "loss : 2.405231 [94720/100000]\n",
            "loss : 10.424770 [95040/100000]\n",
            "loss : 0.206246 [95360/100000]\n",
            "loss : 3.817716 [95680/100000]\n",
            "loss : 0.084348 [96000/100000]\n",
            "loss : 0.417398 [96320/100000]\n",
            "loss : 4.616201 [96640/100000]\n",
            "loss : 0.098880 [96960/100000]\n",
            "loss : 0.918264 [97280/100000]\n",
            "loss : 5.658138 [97600/100000]\n",
            "loss : 0.111300 [97920/100000]\n",
            "loss : 1.823810 [98240/100000]\n",
            "loss : 7.800299 [98560/100000]\n",
            "loss : 0.172929 [98880/100000]\n",
            "loss : 3.063563 [99200/100000]\n",
            "loss : 7.298786 [99520/100000]\n",
            "loss : 0.230120 [99840/100000]\n",
            "Test Error: \n",
            " Accuracy: 0.0%, Avg loss: 11.673677 \n",
            "\n",
            "DONE!!!!!!!!!!!!!!!!!!!!!!!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fashion MNIST 이미지를 활용하는 방법"
      ],
      "metadata": {
        "id": "jD-XglL5B6Et"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "eMUgY9tuDbZO"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = torchvision.datasets.FashionMNIST( # (60000, 28, 28)\n",
        "    root='./data/',\n",
        "    train = True,\n",
        "    transform = ToTensor(),\n",
        "    download=True,\n",
        ")\n",
        "\n",
        "test_data = torchvision.datasets.FashionMNIST(\n",
        "    root='./data/',\n",
        "    train=False,\n",
        "    transform=ToTensor(),\n",
        "    download=True,\n",
        ")\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size=128)\n",
        "test_dataloader = DataLoader(test_data, batch_size=128)"
      ],
      "metadata": {
        "id": "lQXiU4W8D3LQ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋이 제대로 들어갔는지 시각화해서 확인\n",
        "\n",
        "labels_map = {\n",
        "    0: 'T-Shirt',\n",
        "    1: 'Trouser',\n",
        "    2: 'Pullover',\n",
        "    3: 'Dress',\n",
        "    4: 'Coat',\n",
        "    5: 'Sandal',\n",
        "    6: 'Shirt',\n",
        "    7: 'Sneaker',\n",
        "    8: 'Bag',\n",
        "    9: 'Ankle Boot',\n",
        "}\n",
        "\n",
        "figure = plt.figure(figsize=(8,8))\n",
        "cols, rows = 3, 3\n",
        "for i in range(1, rows*cols+1):\n",
        "  sample_idx = torch.randint(len(training_data), size=(1,)).item() # Tensor에서 값이 하나만 있는 걸 꺼낼때 사용\n",
        "  img, label = training_data[sample_idx]\n",
        "  figure.add_subplot(rows, cols, i)\n",
        "  plt.title(labels_map[label])\n",
        "  plt.axis('off') # 축 눈금등을 없애주는 메소드, 기본값:True\n",
        "  plt.imshow(img.squeeze(), cmap='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XTKNHpTGHx6h",
        "outputId": "6c405735-953f-48f5-9eff-21e590fca9f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x576 with 9 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from torchvision.io import read_image # ???"
      ],
      "metadata": {
        "id": "3Jy7vT0HP5a1"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomImageDataset(Dataset):\n",
        "  def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
        "    self.img_labels = pd.read_csv(annotations_file, names=['file_name', 'label'])\n",
        "    self.img_dir = img_dir\n",
        "    self.transform = transform\n",
        "    self.target_transform = target_transform\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.img_labels)\n",
        "\n",
        "  def __getitem__(self, idx):"
      ],
      "metadata": {
        "id": "4sa87Y26QCoG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}